{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc04fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bf4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f56a3",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d88b2",
   "metadata": {},
   "source": [
    "## pretrain vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff1c265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./res_data/pretrain_vec','r') as f:\n",
    "    pretrain_vec = np.loadtxt(f,delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a81aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrain_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a15f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_list = dgl.load_graphs('./res_data/ad_graphs.dgl')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75f1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ad_index = open('./res_data/ad_index','rb')\n",
    "ad_index = pickle.load(f_ad_index)\n",
    "\n",
    "f_index_ad = open('./res_data/index_ad','rb')\n",
    "index_ad = pickle.load(f_index_ad)\n",
    "\n",
    "f_ds_ad_label = open('./res_data/ds_ad_label','rb')\n",
    "ds_ad_label = pickle.load(f_ds_ad_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1976c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [int(i[1]) for i in sorted(index_ad.items(),key = lambda x:x[0])]:\n",
    "    #print(i)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df6d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,g in enumerate(graphs_list):\n",
    "    graphs_list[index].edata['w'] =  graphs_list[index].edata['w'].view(-1,1)\n",
    "    #graphs_list[index] = dgl.add_self_loop(graphs_list[index])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5106dcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7af4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "g0 = graphs_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b733d",
   "metadata": {},
   "source": [
    "# generate label graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6600a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegGraph(g):\n",
    "    u, v = g.edges()\n",
    "    adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())),shape=(g.number_of_nodes(),g.number_of_nodes()))\n",
    "    #print(adj.shape)\n",
    "    adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "    neg_u, neg_v = np.where(adj_neg != 0)\n",
    "    rand_index = np.random.permutation(len(neg_u))\n",
    "    neg_u = neg_u[rand_index][:g.num_edges()*40]\n",
    "    neg_v = neg_v[rand_index][:g.num_edges()*40]\n",
    "    gn = dgl.graph(([],[]),num_nodes=g.number_of_nodes())\n",
    "    gn.add_edges(u,v,{'w':g.edata['w'].view(-1)})\n",
    "    gn.add_edges(neg_u, neg_v,{'w':torch.zeros(neg_u.shape[0])})\n",
    "    #gn.add_edges(u,v,{'w':g.edata['w'].view(-1)})\n",
    "    return gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4066dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_graphs_list = []\n",
    "label_graphs_list = []\n",
    "for g in graphs_list:\n",
    "    pos_graphs_list.append(g)\n",
    "    #graphs_list[index] = dgl.add_self_loop(graphs_list[index])\n",
    "    label_graphs_list.append(getNegGraph(g))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859f588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_graphs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694693a",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "739816db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "from dgl.nn import SAGEConv\n",
    "from dgl.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee5e1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GCN ,self).__init__()\n",
    "        #self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        #self.conv2 = GraphConv(h_feats, num_classes)\n",
    "        self.conv1 = SAGEConv(in_feats,h_feats,aggregator_type='mean',feat_drop=0)\n",
    "        self.conv2 = SAGEConv(h_feats,h_feats,aggregator_type='mean',feat_drop=0)\n",
    "        self.do = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, g, in_feat):\n",
    "        edge_weight=g.edata['w']\n",
    "        if model.training:\n",
    "            #edge_weight = self.do(edge_weight)\n",
    "            pass\n",
    "        h = self.conv1(g, in_feat,edge_weight=edge_weight)\n",
    "        #h = self.conv1(g, in_feat)\n",
    "        '''\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = in_feat\n",
    "            msg_fn = dgl.function.u_mul_e('h', 'w', 'm')\n",
    "            #msg_fn = dgl.function.copy_src('h', 'm')\n",
    "            reduce_fn = dgl.function.mean('m', 'neigh')\n",
    "            g.update_all(msg_fn,reduce_fn)\n",
    "            h = g.ndata['neigh']+g.ndata['h']\n",
    "            #print('after in_feat',h[0])\n",
    "            #h = self.conv1(g, in_feat)\n",
    "            h = F.relu(h)\n",
    "            return h\n",
    "        '''  \n",
    "        h = F.tanh(h)\n",
    "        #h = F.relu(h)\n",
    "        #h = self.conv2(g, h,edge_weight=g.edata['w'])\n",
    "        #h = self.conv2(g, h)\n",
    "        #print('h',h[0])\n",
    "        #print('h_norm',torch.norm(h,dim=1,keepdim=True))\n",
    "        ##是否进行 归一化！！！！\n",
    "        #h = h/(torch.norm(h,dim=1,keepdim=True))\n",
    "        #print('after norm',h[0])\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4fa33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedGCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats,num_classes):\n",
    "        super(embedGCN ,self).__init__()\n",
    "        self.node_embed = nn.Embedding(in_feats, 128)\n",
    "        self.W0 = nn.Linear(128, h_feats)\n",
    "        \n",
    "        self.gcn = GCN(h_feats, h_feats)\n",
    "        \n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "        self.reset_param()\n",
    "        #self.node_embed.weight.data = torch.nn.Parameter(torch.tensor(pretrain_vec).float())\n",
    "        \n",
    "    def forward(self, g,feat=None):\n",
    "        if feat == None:\n",
    "            new_feat = self.node_embed(torch.arange(start=0,end=g.num_nodes(),dtype=torch.int64))\n",
    "            new_feat = self.W0(new_feat)\n",
    "            #new_feat = F.sigmoid(new_feat)\n",
    "            #new_feat = new_feat/(torch.norm(new_feat,dim=0))\n",
    "        else:\n",
    "            new_feat = feat\n",
    "              \n",
    "        #print(new_feat.shape)\n",
    "        #print(new_feat[0])\n",
    "        h = self.gcn(g,new_feat)\n",
    "        return h\n",
    "    \n",
    "    def apply_edges(self,edges):\n",
    "        h = edges.src['h']\n",
    "        l = edges.dst['h']#-edges.dst['h']\n",
    "        score = (h*l).sum(dim=-1).view(-1)\n",
    "        \n",
    "        if not model.training:\n",
    "            print('dot score',score)\n",
    "            print('cos score',torch.nn.functional.cosine_similarity(h,l,dim=1))\n",
    "        \n",
    "        rand_mask = (torch.rand(score.shape[0])>0.5)*1\n",
    "        return {'edge_score':score}\n",
    "    \n",
    "    def edgeout1(self,g,feat):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feat\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "    \n",
    "    def edgeout(self,g):\n",
    "        with g.local_scope():\n",
    "            feat = self.forward(g)\n",
    "            g.ndata['h'] = feat\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "        \n",
    "    def message_func(self, edges):\n",
    "        return {'e': edges.data['edge_score']}    \n",
    "    \n",
    "    def exp_msg(self,edges):\n",
    "        #print('before_add_fix',torch.exp(edges.data['norm_msg']))\n",
    "        #print('after_add_fix',torch.exp(edges.data['norm_msg'])+0.0001)\n",
    "        \n",
    "        return {'exp_msg': torch.exp(edges.data['norm_msg'])}\n",
    "    \n",
    "    def sum_msg(self, nodes):\n",
    "        h = torch.sum( nodes.mailbox['exp_msg'], dim=1)\n",
    "        #print('before fix zero',h)\n",
    "        #h += torch.ones(h.shape[0])*0.00001\n",
    "        #print('after fix zero',h)\n",
    "        return {'edge_sum': h}\n",
    "       \n",
    "    def GCNOut(self,g):\n",
    "        pass\n",
    "    \n",
    "    def edgeout2(self,g,debug=False):\n",
    "        with g.local_scope():\n",
    "            feat = self.forward(g)\n",
    "            #feat = self.node_embed(torch.arange(start=0,end=g.num_nodes(),dtype=torch.int64))\n",
    "            return self.edgeout3(g,feat,debug)       \n",
    "        \n",
    "    def edgeout3(self,g,feat,debug=False):\n",
    "        with g.local_scope():\n",
    "            #print('node_feat',feat[:100])\n",
    "            g.ndata['h'] = feat\n",
    "            #print('feat',feat.shape)\n",
    "            \n",
    "            rg = dgl.reverse(g,copy_edata=True)\n",
    "\n",
    "            ##compute edge_score before exp->get edge_score\n",
    "            rg.apply_edges(self.apply_edges)\n",
    "            ##compute max_edge_score of neighbour-> max_msg\n",
    "            rg.update_all(self.message_func, dgl.function.max('e', 'max_msg'))\n",
    "            \n",
    "            if debug:\n",
    "                print('rg src_msg',rg.edata['edge_score'])\n",
    "                print('rg max_msg of node ',rg.ndata['max_msg'])\n",
    "            ##compute\n",
    "            rg.apply_edges(dgl.function.e_sub_v('edge_score', 'max_msg', 'norm_msg'))\n",
    "            \n",
    "            if debug:\n",
    "                print('rg norm edge  score',rg.edata['norm_msg'])\n",
    "             \n",
    "            ## get exp score -> exp_msg\n",
    "            rg.apply_edges(self.exp_msg)\n",
    "            \n",
    "            if debug:\n",
    "                print('rg exp norm edge  score',rg.edata['exp_msg'])\n",
    "            \n",
    "            rg.update_all(dgl.function.copy_e('exp_msg','exp_msg'),reduce_func=self.sum_msg)\n",
    "            \n",
    "            rg.apply_edges(dgl.function.e_div_v('exp_msg', 'edge_sum', 'm'))\n",
    "                       \n",
    "            if debug:\n",
    "                print('rg sum_meg',rg.ndata['edge_sum'])\n",
    "                print('rg final  score',rg.edata['m'])\n",
    "            \n",
    "            '''\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            if debug:\n",
    "                print('g src_msg',g.edata['score'])\n",
    "            g.apply_edges(dgl.function.e_div_v('score', 'edge_sum', 'm'))\n",
    "            if debug:\n",
    "                print('g sum_meg',g.ndata['edge_sum'])  \n",
    "                print('g edge score',g.edata['m'])\n",
    "            ''' \n",
    "            return rg.edata['m']\n",
    "    \n",
    "    def reset_param(self):\n",
    "        torch.nn.init.xavier_uniform_(self.node_embed.weight, gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb88b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seqEmbedGCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(seqEmbedGCN ,self).__init__()\n",
    "        self.embedGCN = embedGCN(in_feats, h_feats, h_feats)\n",
    "        self.rnn = nn.LSTM(h_feats,h_feats,num_layers=1,batch_first=False)\n",
    "        self.outlayer = nn.Linear(h_feats,num_classes)\n",
    "        self.sfx = nn.Softmax(dim=2)\n",
    "        #self.embedGCN.node_embed.weight.data = torch.nn.Parameter(torch.eye(in_feats, h_feats))\n",
    "        \n",
    "    def forward(self, graphs,debug=False):\n",
    "        ##graphs: \n",
    "        seq_input = torch.stack([self.embedGCN(g) for g in graphs],0)\n",
    "        #seq_input = torch.randn(2, 368, 16): num_of_graph[seq] , num_of_node[batch],num_of_dim\n",
    "        if debug:\n",
    "            print('input',seq_input.shape)\n",
    "\n",
    "        output, (hn, cn) = self.rnn(seq_input)\n",
    "        if debug:\n",
    "            print('o',output.shape)\n",
    "            print('h',hn.shape)\n",
    "            print('c',cn.shape)\n",
    "        ##output:2, 368, 16 ; num_of_graph[seq] , num_of_node[batch],num_of_dim\n",
    "        output = self.outlayer(output)\n",
    "        if debug:\n",
    "            print('last_out',output.shape)\n",
    "        return self.sfx(output)\n",
    "    \n",
    "    def getGCNout(self,graphs,debug=False):\n",
    "        return self.embedGCN(g)\n",
    "    \n",
    "    def getGCNedge(self,graph,node_feat,debug=False):\n",
    "        return self.embedGCN.edgeout3(graph,node_feat,debug)\n",
    "    \n",
    "    def getGCNedge2(self,graph,debug=False):\n",
    "        return self.embedGCN.edgeout2(graph,debug)    \n",
    "    \n",
    "\n",
    "    def getLSTMout(self,graphs):\n",
    "        seq_input = torch.stack([self.embedGCN(g) for g in graphs],0)\n",
    "        output, (hn, cn) = self.rnn(seq_input)\n",
    "        return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3df77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g0n = getNegGraph(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79db2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seqEmbedGCN(g0.num_nodes(),16,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dbd615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bingfa.zjq/workingspace/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "res = model.getGCNedge(g0n,model.getGCNout(g0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff5cc2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114582])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170b82de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index,i,j,m,k,n in zip(range(res.shape[0]),g0.edges(form='all')[0],g0.edges(form='all')[1],\\\n",
    "                           res,[0.0177, 0.0087, 0.0316, 0.0112, 0.0207, 0.0329, 0.0519, 0.1916, 0.1023,\n",
    "        0.0177, 0.0064, 0.0106, 1.0000, 0.1873, 0.1023, 0.1873, 0.0843, 0.0267,\n",
    "        0.0085, 0.0078, 0.0329, 0.0316, 0.0087, 0.0207, 0.0045, 0.1916, 0.0099,\n",
    "        0.0213, 1.0000, 0.0843, 0.0258, 0.0147, 0.0519, 0.0167],g0.edata['w']):\n",
    "    #print(index,i,j,m,k,n)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64514c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model([g0,g0n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7580569c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0202, 0.0228, 0.0208, 0.0234, 0.0155, 0.0151, 0.0211, 0.0199, 0.0213,\n",
       "        0.0167, 0.0183, 0.0198, 0.0204, 0.0157, 0.0202, 0.0199, 0.0172, 0.0171,\n",
       "        0.0201, 0.0246, 0.0238, 0.0185, 0.0206, 0.0245, 0.0203, 0.0177, 0.0197,\n",
       "        0.0231, 0.0213, 0.0168, 0.0176, 0.0152, 0.0191, 0.0185, 0.0179, 0.0222,\n",
       "        0.0243, 0.0212, 0.0224, 0.0211, 0.0207, 0.0160, 0.0215, 0.0202, 0.0155,\n",
       "        0.0199, 0.0197, 0.0242, 0.0248, 0.0214], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229e783",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d86ec16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_train(graphs_list, model,debug=False):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),weight_decay=0, lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    ##node loss\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    bce_loss = torch.nn.BCELoss()\n",
    "    \n",
    "    epochs = 501#1001\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        beg_pos = 0\n",
    "        seq_len = 4\n",
    "        \n",
    "        for step in range(seq_len,len(graphs_list)+seq_len,seq_len):\n",
    "            model.train()\n",
    "            \n",
    "            input_node_graph =graphs_list[beg_pos:step]\n",
    "            input_edge_graph = [getNegGraph(g) for g in input_node_graph]\n",
    "\n",
    "            if len(input_node_graph) != seq_len:\n",
    "                break\n",
    " \n",
    "            #print(input_edge_graph)\n",
    "\n",
    "            ##get pred_edge_score\n",
    "            pred_edge_scores = torch.cat([model.getGCNedge(edge_g,model.getGCNout(node_g)) \\\n",
    "                                    for  edge_g,node_g in zip(input_edge_graph,\\\n",
    "                                                              input_node_graph)])\n",
    "            \n",
    "            #print('pred_edge_score_shape',pred_edge_scores.shape)\n",
    "            \n",
    "            \n",
    "            #edges_mask = torch.cat([(i.edata['w']!=0)*1 for i in input_node_graph])\n",
    "            #print('edge_mask_shape',edges_mask.shape)\n",
    "            \n",
    "            label_edge_weight = torch.cat([i.edata['w'] for i in input_edge_graph])\n",
    "            #print('label_edge_weight_shape',label_edge_weight.shape)\n",
    "        \n",
    "            \n",
    "            #return\n",
    "            ##edge_loss \n",
    "            pred_edge_scores = pred_edge_scores  + 1e-7\n",
    "            pred_edge_scores = torch.log(pred_edge_scores)\n",
    "            #print('log edge_score',edge_score)  \n",
    "\n",
    "            edge_loss = -1*(label_edge_weight*pred_edge_scores ).sum()/(label_edge_weight.sum())\n",
    "            \n",
    "            pred_node_score = model(input_node_graph)\n",
    "\n",
    "            label_node_score = torch.stack([i.ndata['y'] for i in input_node_graph],dim=0)\n",
    "            node_loss = kl_loss(torch.log(pred_node_score),label_node_score)\n",
    "            #return \n",
    "            \n",
    "            \n",
    "            #edge_loss = -1*(edge_mask*edge_score).sum()/(edge_mask.sum())\n",
    "\n",
    "            #edge_loss = kl_loss(edge_score,edge_weight)\n",
    "\n",
    "            #print('edge_loss',edge_loss)\n",
    "            #print('node_vec',model.embedGCN.node_embed.weight)\n",
    "\n",
    "            alpha = 0.9\n",
    "            loss=alpha*(torch.abs(edge_loss-1.9)+1.9)+ (1-alpha)*node_loss\n",
    "\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            with torch.autograd.set_detect_anomaly(True):\n",
    "                loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2, norm_type=2)\n",
    "            optimizer.step()\n",
    "\n",
    "            if e % 10 == 0:\n",
    "                #print('node_vec',model.node_embed.weight[1:])\n",
    "                #print('grad',model.node_embed.weight.grad[1:])\n",
    "                pass\n",
    "\n",
    "            if e%(20) ==0 :\n",
    "                scheduler.step()\n",
    "\n",
    "\n",
    "            if e % 10 == 0:\n",
    "                #print('eval')\n",
    "                print('epoch:%d,step:%d,loss:%f，edge_loss:%f,node_loss:%f'%\\\n",
    "                      (e,step,loss,edge_loss,node_loss))\n",
    "                model.eval()\n",
    "                #edge_score = model.edgeout3(g0n,model(g))\n",
    "                #print('edge_score',edge_score)  \n",
    "                #print('sum_edge_score',edge_score.sum())\n",
    "                #scheduler.step()\n",
    "                #print('lr',optimizer.state_dict()['param_groups'][0]['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7c50d48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = graphs_list[0]\n",
    "model = seqEmbedGCN(g.num_nodes(),128,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38814460",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bingfa.zjq/workingspace/anaconda3/lib/python3.7/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,step:4,loss:21.416206，edge_loss:5.818824,node_loss:161.792664\n"
     ]
    }
   ],
   "source": [
    "seq_train(graphs_list, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80705e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#res=model.getGCNedge2(g0n,True)\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b1129",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res=model.getGCNedge(g0n,model.getGCNout(g),True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52bc22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " for index,i,j,m,n in zip(range(res.shape[0]),g0n.edges(form='all')[0],g0n.edges(form='all')[1],\\\n",
    "                         model.getGCNedge(g0n,model.getGCNout(g)),g0n.edata['w']):\n",
    "    print(index,i.numpy(),j.numpy(),index_ad[int(i.numpy())],index_ad[int(j.numpy())],m,n)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edata['w'].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.embedGCN.node_embed(torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022512d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.embedGCN.node_embed(torch.tensor(ad_index['110000']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74b04b",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_vec = model.getGCNout(g0)\n",
    "def getsim(a,b):\n",
    "    print('cos',torch.nn.functional.cosine_similarity(node_vec[ad_index[a]],node_vec[ad_index[b]],dim=0))\n",
    "    print('dot',(node_vec[ad_index[a]]*node_vec[ad_index[b]]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a389c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "getsim('130200','120000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "getsim('130200','130600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db5ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "getsim('130200','130800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5639d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosvalue(ad_a,ad_b):\n",
    "    a = model.embedGCN.node_embed(torch.tensor(ad_index[ad_a]))\n",
    "    b = model.embedGCN.node_embed(torch.tensor(ad_index[ad_b]))\n",
    "    return torch.nn.functional.cosine_similarity(a,b,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.getGCNout(g0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee427db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosvalue2(ad_a,ad_b):\n",
    "    a = model.getGCNout(graphs_list[-1])[ad_index[ad_a]]\n",
    "    b = model.getGCNout(graphs_list[-1])[ad_index[ad_b]]\n",
    "    return torch.nn.functional.cosine_similarity(a,b,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cosvalue2('440300','810000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cosvalue('440100','810000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6eadaf",
   "metadata": {},
   "source": [
    "# dump vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./gnn_embed/vector.txt','w') as f:\n",
    "    np.savetxt(f,X=model.getGCNout(g0).detach().numpy(),delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./gnn_embed/embed_vector.txt','w') as f:\n",
    "    np.savetxt(f,X=model.embedGCN.node_embed.weight.data.detach().numpy(),delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329748ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in index_ad.values():\n",
    "    #print(i)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c7519",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bf909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.datetime.now()\n",
    "timestamp = \"%s-%s-%s-%s-%s\"%(dt.year,dt.month,dt.day,dt.hour,dt.minute)\n",
    "ckPath = './model_res/%s'%(timestamp)  \n",
    "print('timestamp',ckPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), ckPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
